% Chapter: Findings

\section{Findings}
This research does not aim to prove that language models can autonomously design drone shows. Instead, we aim to identify where they help, where they fall short, and under what conditions they might be useful. From that perspective, our expected findings fall into three broad categories:

\begin{enumerate}
  \item \textbf{Insight into the Design Process:} \\
  We expect to develop a clearer understanding of how drone show designers currently translate creative intent into executable formations, where manual effort and iteration slow the process, and what types of tasks could benefit most from partial automation.

  \item \textbf{Assessment of LLM Utility:}
  \begin{itemize}
    \item What kinds of inputs are LLMs good at interpreting?
    \item When do LLMs generate usable formations, and when do they fail?
    \item Do structured prompts lead to more consistent, editable outputs than open-ended ones?
    \item How does LLM behavior vary across models, and what does that imply for design?
  \end{itemize}

  \item \textbf{Design Recommendations for Human-LLM Collaboration:} \\
  We expect to generate recommendations on prompting strategies, interface patterns, and representation formats that improve usability, even if the LLM itself is not always reliable.
\end{enumerate}
Even if the final system is limited in scope or capability, we expect this work to produce a clearer map of the problem space, the potential role of language-based agents, and the design trade-offs involved. The goal is not to validate a specific solution, but to refine the question itself, and give others a better place to start.
