% Chapter: Conclusion

\section{Conclusion}

This project began not with the goal of building a novel system, but with a question: Does using large language models to guide drone swarm choreography meaningfully help anyone, and if so, how? Through a critical review of existing academic literature and commercial tools, we identified a recurring pattern: LLMs are typically used as translators for natural language, generating intermediate representations like waypoints or geometric shapes. However, these systems rarely consider how real-world professionals design drone shows, nor do they evaluate whether the outputs are usable, interpretable, or worth trusting.

Our proposed work addresses that gap. By developing a modular, prompt-driven agent and studying how users interact with it, we aim to uncover not just whether LLMs are technically capable, but whether they are practically valuable, for whom, in which contexts, and under what constraints.

We are not claiming that LLMs will revolutionize drone choreography. Instead, we aim to:
\begin{itemize}
  \item Clarify where they genuinely reduce creative friction.
  \item Identify when structured design tools are preferable.
  \item Explore what an intelligent assistant for formation design might actually look like, not someday, but now, in modest and testable ways.
\end{itemize}

In doing so, we hope to contribute not just a prototype, but a set of grounded insights that future researchers, tool-builders, and designers can build on. Even if the output is imperfect, the process, rooted in dialogue, curiosity, and iteration, offers a different kind of value: a framework for building more human-centered, interpretable systems in creative robotics.

